# Apresentação

Olá, sou o Allan Gabriel, Moro em Salto Grande - SP, curso segurança da informação na FATEC Ourinhos e atualmente estou no 6° semestre, não tenho experiências profissionais na área de tecnologia, gosto de praticar atividades físicas. 

# Portfólio de estudos

## Curso de Linux para Desenvolvedores (c/ terminal, Shell, Apache e +)

### Seção 1: Introdução 
Nessa seção aprendi a instalar o Linux e a ferramenta de virtualização, a que escolhi foi o virtual box

### Seção 2: Teoria sobre o Linux
Nessa seção aprendi sobre a parte teórica do Linux, distribuições que são diferentes versões do linux, sobre o kernel que é o componente que liga os processos executados do computador com a interface central, também foi citado as vantagens de se utilizar Linux.

### Seção 3: Linux Fundamental
Nessa seção aprendi sobre os comandos básicos do Linux para entrar em pastas, listar o que tem nelas, mostrar o conteúdo de arquivos de texto e criar arquivos

### Seção 4: Gerenciamento de diretórios e arquivos
Nessa seção aprendi a criar, remover, copiar, mover pastas e arquivos, também o comando bônus “pwd” para localizar em que pasta o usuário está.

### Seção 5: Gerenciamento de pacotes/aplicativos
Nessa seção aprendi a atualizar repositórios, instalar e deletar aplicativos e atualizar o Linux

### Seção 6: Filtro de buscas de arquivos e diretório
Nessa seção aprendi a usar comandos para localizar coisas especificas dentro de arquivos, geralmente de texto, com os comando head, tail, grep, find e locate

### Seção 7: Editores de texto mais utilizados
Aprendi sobre os editores de textos mais utilizados. 
Começando pelo nano, que tem uma interface bem detalhada e intuitiva, as funções são ativadas apertando ctrl+ (tecla referente), podendo ser para copiar e colar, salvar arquivo, recortar, procurar e entre outros
Já o editor vim, eu tenho certa familiaridade por ser um editor de texto que utilizo na faculdade, porém revendo o curso descobri coisas novas, como a função de procurar e substituir palavras e frases.

### Seção 8: Gerenciamento de usuários e grupos
Nessa seção eu aprendi a gerenciar os usuários, inicialmente funções básicas como criar e apagar, renomear, bloquear e desbloquear, mover usuários para outros grupos.
No final também tem extras de como virar um super usuário usando o “sudo su”  e trocando a senha do usuário com o “passwd”

### Seção 9: Gerenciamento de permissões
Nessa seção aprendi sobre como dar permissões para cada grupo, usuário, diretórios ou arquivos. As permissões são dividas em “r” (read) indicando que o usuário ou grupo pode ler o arquivo, “w” (write) indicando que o usuário ou grupo pode escrever e editar o arquivo e “x” (execute) indicando que o usuário ou grupo pode executar o arquivo.

### Seção 10: Gerenciamento básico de redes
O módulo começa com explicação de alguns protocolos de rede que já utilizei muito na faculdade sendo eles TCP, UDP, DNS, também foi explicado sobre as portas.
Na parte prática aprendi sobre os comandos básicos para obter informações entre as trocas de pacotes entre as redes e a verificar informações da minha própria rede

### Seção 11: Compactação e descompactação de arquivos e diretórios
Aprendi a compactar e descompactar arquivos com o comando “tar” e “zip”

## Curso de Git e GitHub do básico ao avançado (c/ gist e GitHub Pages)

### Seção 1: Introdução e instalação das dependências
Aprendi sobre o que é github e como instalar as ferramentas importantes para começar a utilizá-lo.

### Seção 2: Git Fundamental
Assim como está no titulo da seção, aprendi sobre o básico e essencial sobre o git, como git init, git commit, git push e etc, o básico necessário para me adaptar aos sistema de repositório das empresas.

### Seção 3: Trabalhando com branches
Aprendi usar os recursos de Branch, que é criar uma variação do código principal, posteriormente pode ser integrado ao mesmo, com isso, a maioria do que é necessário para se usar em uma empresa se software foi ensinado.

### Seção 4: Compartilhamento e atualização de repositórios
Aprendi sobre o comando “git fetch” para identificar uma Branch que não foi atualizada para o sistema ainda, também a como mudar a origem do repositório e por fim sobre os submódulos.

### Seção 5: Análise e inspeção de repositórios
Seção básica que ensina alguns comandos complementares para exibir informações adicionais para uma melhor inspeção do repositório.

### Seção 6: Administração de repositórios
Aprendi comandos que podem ajudar para administração do repositório, comandos para verificar a integridade dos arquivos, limpar arquivos que não foram "tracked" e arquivos inúteis, um novo comando de log que mostra outras coisas e por fim a compactar o repositório.

### Seção 7: Melhorando os commits do projeto
Aprendi de forma mais teórica sobre os commits em uma situação empresarial, que a melhor maneira de ser feito é escrevendo de maneira concisa e objetiva o que foi feito no commit, evitar fazer commits a todo momento, também aprendi como criar uma branch privada.

### Seção 8: Explorando e entendendo Github
Nessa seção aprendi sobre a maior parte do que é possivel fazer com o repositório do github e sobre como criar gists que são códigos menores e simples que podem usados pra resolver problemas.

### Seção 9: Markdown do básico ao avançado
Aprendi a como estilizar os textos no github com o markdown, com titulos, listas, lista de tarefas, imagens, links. Com esse conhecimento posso deixar meus futuros projetos mais atraentes para clientes e colaboradores. 

## Curso de SQL para Análise de Dados: Do básico ao avançado

### Seção 2: Configuração do ambiente de trabalhado
Nessa seção eu aprendi a instalar e configurar o aplicativo pgadmin, necessário para o curso

### Seção 3: Comando básicos
Nessa seção, aprendi sobre os comandos básicos do SQL, incluindo SELECT, DISTINCT, WHERE, ORDER BY e LIMIT. Entendi como esses comandos são fundamentais para a manipulação de dados em bancos de dados relacionais, permitindo a seleção, filtragem, ordenação e limitação de resultados. Além disso, aprendi sobre a importância de dominar esses comandos para realizar consultas eficientes e obter os dados desejados de forma rápida e precisa.

### Seção 4: Operadores
Nessa seção, adquiri conhecimentos sobre os operadores em SQL, incluindo operadores aritméticos, de comparação e lógicos. Entendi como cada tipo de operador é utilizado e como eles podem ser combinados para criar consultas SQL mais precisas.

### Seção 5: Funções agregadas
Nesta seção, aprofundei meu conhecimento sobre o uso dos comandos GROUP BY e HAVING em SQL. Isso pode ser útil em relatórios e análises onde se deseja focar em resultados específicos.

### Seção 6: Join
Nesta seção, me dediquei ao estudo do comando JOIN em SQL, essencial para combinar registros de duas ou mais tabelas em um banco de dados, esse conhecimento é muito importante para realizar consultas complexas.

### Seção 7: Union
Nesta seção, explorei o comando UNION em SQL, que é usado para combinar os resultados de duas ou mais consultas em um único conjunto de resultados.

### Seção 8: Subqueries 
Nesta seção, me dediquei ao estudo de subqueries em SQL, que são consultas dentro de outras consultas. Este conhecimento é crucial para a criação de consultas complexas necessárias em ambientes de banco de dados avançados

### Seção 9: Tratamento de dados
 Nesta seção, aprofundei meu conhecimento no tratamento de dados em SQL, abrangendo áreas importantes como tratamento de dados, tratamento de texto e tratamento de datas.
No tratamento de dados, aprendi sobre a padronização de informações armazenadas em bancos de dados relacionais para garantir consistência e integridade.
Em tratamento de texto, aprendi a manipular strings de texto de forma mais eficientes.
Em relação ao tratamento de datas, explorei a manipulação de valores de data e hora, extração de componentes de data (como dia, mês e ano), cálculos de diferença entre datas etc.
Terminando com as funções que pode ser útil em alguns casos, para automatizar algumas ações em SQL.
Essas habilidades são fundamentais para garantir a qualidade e integridade dos dados em bancos de dados SQL.

### Seção 10: Manipução de tabelas
Nesta seção, aprofundei meu conhecimento em manipulação de dados em bancos de dados, abordando desde a criação e exclusão de tabelas até operações de inserção, atualização e exclusão de registros.

## Curso de AWS: Sales Accreditation
* Aprendi sobre a computação em nuvem e os serviços oferecidos pela AWS. Exploramos os motivos pelos quais os clientes optam pela AWS e como esses serviços facilitam a transformação digital das empresas.
* Compreendi o valor comercial da AWS. Através do AWS Cloud Value Framework, aprendi a avaliar os benefícios econômicos, a produtividade da equipe, a resiliência operacional e a agilidade empresarial proporcionados pela adoção da nuvem da AWS.
* Foi abordado como lidar com objeções comuns à adoção da nuvem, como custo, segurança, conformidade, perda de controle e habilidades técnicas. Além disso, estratégias para superar essas objeções e promover a adoção da nuvem.
* Aprendi sobre a venda conjunta com a AWS, compreendendo as práticas recomendadas para trabalhar em parceria com a AWS e explorando os programas de financiamento disponíveis para os parceiros da AWS.
* O curso encerrou com um resumo abrangente e um teste de credenciamento para avaliar meu conhecimento e compreensão do curso de vendas para parceiros da AWS.

## Curso de AWS: Aspectos econômicos da nuvem
Nesta seção, explorei uma variedade de tópicos relacionados à computação em nuvem, com foco no uso da AWS. Discuti aspectos econômicos, operacionais e estratégicos, desde o valor da nuvem até a redução de custos, produtividade da equipe, resiliência operacional, agilidade empresarial, sustentabilidade e gerenciamento financeiro na nuvem. Concluí com uma lição sobre avaliação do portfólio de migração, demonstrando como acessar e utilizar a ferramenta MPA para planejar uma migração para a nuvem com sucesso.

## Curso de AWS: Credenciamento (Técnico)
Neste Curso, eu explorei elementos técnicos essenciais da AWS, incluindo seus serviços principais e como eles se encaixam no ecossistema de computação em nuvem. Aprendi sobre os principais componentes da AWS, como computação, armazenamento, rede e banco de dados, e como eles podem ser utilizados para construir e escalar aplicações na nuvem. Além disso, os conceitos fundamentais de segurança, escalabilidade e disponibilidade na nuvem, e como a AWS fornece ferramentas e serviços para nos ajudar a alcançar esses objetivos. Ao longo do curso, explorei exemplos práticos para ilustrar os conceitos apresentados, permitindo uma compreensão mais profunda dos princípios e práticas da AWS.

## Curso de Python (Sprint 3)
* Neste curso, mergulhei fundo no universo da programação em Python, uma linguagem que sempre me interessou pela sua simplicidade. explorei desde os conceitos mais básicos até os mais complexos. Aprendi sobre variáveis, operadores, estruturas de controle como loops e condicionais.
* Conforme avançava, explorei os fundamentos essenciais da linguagem, como manipulação de listas, dicionários e strings. E à medida que me aprofundei, foi discutido tópicos mais avançados, como funções, classes e herança, sempre com exemplos práticos para facilitar meu entendimento.
* Explorei também os princípios da programação orientada a objetos, uma abordagem poderosa para organizar e estruturar o código de forma mais modular e reutilizável.
* Também aprendi sobre gerenciamento de pacotes, essencial para trabalhar com bibliotecas externas e expandir as capacidades do Python.


## Curso de Python (Sprint 4)
Nessa parte do curso, aprendi sobre o mundo da programação funcional. Explorei os fundamentos da programação funcional, incluindo o uso de funções de alta ordem, imutabilidade de dados e expressões lambda.
Descobri como a programação funcional pode simplificar o desenvolvimento de software, tornando o código mais conciso, legível e fácil de testar. Ao longo da seção, mergulhei em exemplos práticos e exercícios para aprimorar minha compreensão desses conceitos e como aplicá-los em meu próprio projeto.

## Curso de Docker
* Nesse curso, mergulhei no mundo dos containers, explorando desde conceitos básicos até tópicos avançados de orquestração. Comecei com uma introdução para entender como os containers funcionam e por que são tão populares na indústria de tecnologia.
* Avancei para aprender a criar e gerenciar imagens de containers, aproveitando ao máximo as funcionalidades do Docker. Explorei também o uso de volumes para persistência de dados e como conectar containers através de redes para comunicação entre eles.
* Além disso, adentrei no mundo do YAML, uma linguagem de marcação utilizada para definir configurações de forma legível e estruturada. Descobri como gerenciar múltiplos containers de forma eficiente usando o Docker Compose e como escalar essas aplicações com o Docker Swarm para orquestração de clusters.
* Por fim, explorei as capacidades avançadas de orquestração oferecidas pelo Kubernetes, uma ferramenta poderosa para gerenciar containers em escala. Encerrei a seção com uma visão geral e sugestões para os próximos passos, incentivando a continuidade do aprendizado nesse fascinante campo da tecnologia de containers.

## Jogo da AWS: Cloud Quest
Essa Ferramenta da AWS transforma conceitos complexos em experiências interativas que instigam o usuário a aprender de forma divertida e visualmente atrativa.
O jogo não apenas apresenta informações, mas também exige que o jogador aplique o que aprendeu em cenários simulados, o que ajuda muito na fixação do conteúdo.
Em conclusão, minha experiência com o jogo foi extremamente positiva. Ele é uma ferramenta excelente para iniciantes e para pessoas que querem aprender de forma mais prática

## Curso-padrão de preparação para o exame: AWS Certified Cloud Practitioner (CLF-C02) 
Inicialmente, o curso introduz o exame AWS Certified Cloud Practitioner, oferecendo uma visão geral e um guia completo sobre a estrutura e o conteúdo do exame. Progride então para a familiarização com o formato das questões, explorando o tipo de perguntas que serão encontradas e disponibilizando um conjunto oficial de perguntas para prática em Português (Brasil).

### O conteúdo de preparação é dividido em:
* Conceitos de Nuvem: Onde são definidos os benefícios e princípios da criação de soluções na nuvem pela AWS, estratégias de migração, além de aspectos econômicos relacionados.

* Segurança e Conformidade: Este módulo destaca o modelo de responsabilidade compartilhada da AWS, os conceitos de segurança, governança, conformidade, e gerenciamento de acesso.

* Tecnologia e Serviços em Nuvem: Explora métodos de implantação, a infraestrutura global da AWS, e recursos específicos como computação, banco de dados, rede, armazenamento, além de inteligência artificial, Machine Learning e analytics.

* Cobrança, Preços e Suporte: Discute modelos de preços, recursos de cobrança e orçamento, e opções de suporte técnico da AWS.

Cada módulo tem recursos adicionais para aprofundamento, perguntas de orientação que simulam o ambiente de exame, e uma série de lições introduzidas por especialistas, garantindo uma preparação abrangente e alinhada com as exigências do exame AWS Certified Cloud Practitioner.


## Noções básicas de analytics na AWS – Parte 1
Neste curso de Data Analytics, adquiri conhecimentos fundamentais sobre análise de dados, explorando diferentes tipos de analytics e obtendo uma visão introdutória sobre Machine Learning. Além disso, aprofundei meu entendimento nos 5 Vs do big data: volume, velocidade, variedade, veracidade e valor. Fui capacitado para compreender como esses aspectos impactam a gestão e a análise de grandes conjuntos de dados. Por fim, familiarizei-me com os serviços da AWS projetados para enfrentar cada um dos desafios apresentados pelos 5 Vs do big data, preparando-me para aplicar esses conhecimentos em cenários práticos de análise e solução de problemas complexos de dados.


## Fundamentos de analytics na AWS — Parte 2
Neste curso avançado de arquitetura de dados, explorei data lakes e data warehouses, fundamentais na infraestrutura moderna de dados. Aprofundei-me em AWS Lake Formation para criar e gerenciar data lakes na nuvem. Descobri os benefícios do Amazon Redshift para data warehouses, destacando sua arquitetura sem servidor e capacidades de machine learning.

Estudei os pilares da arquitetura de dados moderna na AWS, incluindo governança de dados, movimentação de dados e arquiteturas de malha. Analisei casos de uso de analytics em diferentes setores e explorei arquiteturas de referência para pipelines de analytics na AWS.

## Serverless Analytics
Neste curso, explorei a complexidade dos dados de clientes e a importância de sua integração e processamento para decisões mais informadas. Mergulhei no uso de tecnologias de ponta como AWS IoT Analytics, Amazon Cognito, AWS Lambda e Amazon SageMaker. Aprendi a transformar dados diversos em insights valiosos, dominando técnicas avançadas para agregação, processamento e armazenamento eficiente de dados, capacitando-me para criar soluções inovadoras e impactantes.

## Introduction to Amazon Athena
Este curso abrange o serviço Amazon Athena e sua aplicação prática no ambiente operacional da AWS. Inclui uma visão geral das etapas básicas para implementar o Amazon Athena usando o Console de Gerenciamento da AWS, com demonstrações de criação de bancos de dados e execução de consultas SQL para validação.

## AWS Glue Getting Started
Neste curso, explorei o AWS Glue, uma ferramenta essencial para integração de dados na nuvem. Aprendi sobre suas funcionalidades principais, incluindo automação de ETL, escalabilidade e integração com outros serviços AWS. Também me familiarizei com o AWS Glue Studio para catalogar metadados e realizar transformações ETL, além de utilizar o AWS Glue DataBrew para perfil de dados e transformações avançadas.

## Amazon EMR Getting Started
Neste curso introdutório sobre Amazon EMR (Elastic MapReduce), explorei sua arquitetura serverless e baseada em clusters, suas aplicações em análise de big data e processamento escalável de dados. Aprendi a configurar e usar clusters Amazon EMR tradicionais baseados em EC2, além de explorar o Amazon EMR Studio para desenvolver e executar trabalhos Spark de maneira eficiente.

## Amazon Redshift Getting Started
Neste curso introdutório sobre Amazon Redshift, explorei sua arquitetura, casos de uso e funcionalidades essenciais. Aprendi sobre a configuração básica de um data warehouse no Amazon Redshift, incluindo a utilização do Query Editor V2 para executar consultas no ambiente Serverless Warehouse. Também adquiri conhecimentos sobre o uso de vistas materializadas para melhorar o desempenho de consultas de BI e a automação de tarefas com stored procedures. Além disso, compreendi a importância da limpeza e gerenciamento de recursos no Amazon Redshift para manter a eficiência operacional do ambiente.

## Best Practices for Data Warehousing with Amazon Redshift
Neste curso sobre Amazon Redshift, explorei a implementação de um data warehouse na nuvem. Aprendi o design básico de tabelas, técnicas de ingestão de dados, gerenciamento de workload e os efeitos do dimensionamento de nó e cluster.

## Amazon QuickSight - Getting Started
Nessa seção, aprendi sobre a introdução ao Amazon QuickSight, uma ferramenta de business intelligence da AWS. Explorei sua arquitetura e casos de uso, além de aprender a criar datasets e análises no QuickSight. Também estudei como personalizar a ferramenta usando temas, publicar dashboards e utilizar o QuickSight Q para fazer perguntas em linguagem natural.

## Formação Spark com Pyspark : o Curso Completo

Nesse curso, aprendi a instalar e configurar o Spark, conhecer os DataFrames e processá-los com transformações e ações. Também aprendi a consultar dados com SQL, criar Views e Joins, e persistir dados em formatos como Parquet e ORC.
Explorei como importar dados de MongoDB, PostgreSQL e arquivos JSON e Parquet, e criar aplicações executáveis na linha de comando. No campo do Machine Learning, aprendi a criar modelos, previsões e Pipelines.
Além disso, aprendi a processar dados em tempo real com Spark Structured Streaming, otimizar o Spark com Cache, Persistência, Particionamento e Bucketing, usar Spark com Jupyter Notebooks, e integrar com Pandas e outras bibliotecas Python. Por fim, aprendi a construir e gerenciar um Cluster Spark.

## Sprints 

1. [Sprint 1](Sprint%201/README.md)
2. [Sprint 2](Sprint%202/README.md)
3. [Sprint 3](Sprint%203/README.md)
4. [Sprint 4](Sprint%204/README.md)
5. [Sprint 5](Sprint%205/README.md)
6. [Sprint 6](Sprint%206/README.md)
7. [Sprint 7](Sprint%207/README.md)

## Desafio

1. [Desafio Final](Desafio/README.md)


